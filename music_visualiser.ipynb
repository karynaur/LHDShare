{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music visualiser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOl70CkinALO",
        "outputId": "48d9efd4-d515-49e3-a566-0eb5b06cae33"
      },
      "source": [
        "!pip install pytorch_pretrained_biggan\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_biggan in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_biggan) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_biggan) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_biggan) (1.17.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_biggan) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_biggan) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_biggan) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_biggan) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_biggan) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_biggan) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_biggan) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_biggan) (0.3.6)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_biggan) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.40 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_biggan) (1.20.40)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.40->boto3->pytorch_pretrained_biggan) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.40->boto3->pytorch_pretrained_biggan) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOsP6jEBmzSe"
      },
      "source": [
        "import librosa\n",
        "import argparse\n",
        "import numpy as np\n",
        "import moviepy.editor as mpy\n",
        "import random\n",
        "import torch\n",
        "from scipy.misc import toimage\n",
        "from tqdm import tqdm\n",
        "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
        "                                       save_as_images, display_in_terminal)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTWiK88cnBpR"
      },
      "source": [
        "song_path=\"/content/The Weeknd - Blinding Lights.mp3\"\n",
        "y, sr = librosa.load(song_path)\n",
        "\n",
        "model_name='biggan-deep-512'\n",
        "frame_length=512\n",
        "pitch_sensitivity=80 * 512 / frame_length\n",
        "tempo_sensitivity=frame_length / (512*4)\n",
        "depth=1\n",
        "num_classes=12\n",
        "sort_classes_by_power=0\n",
        "jitter=1/2\n",
        "truncation=1\n",
        "batch_size=30\n",
        "use_previous_classes,use_previous_vector=0,0\n",
        "outname='out.mp4'\n",
        "smooth_factor=int(20 * 512 / frame_length)\n",
        "seconds=41\n",
        "frame_lim=int(np.floor(seconds*22050/frame_length/batch_size))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SehwZ1SPuYCl",
        "outputId": "b3d4b625-07be-4b71-987d-ce01e58d9e94"
      },
      "source": [
        "sr"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22050"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIBlcZ2npRwf"
      },
      "source": [
        "model = BigGAN.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrertbC6pSJ8"
      },
      "source": [
        "spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000, hop_length=frame_length)\n",
        "\n",
        "#get mean power at each time point\n",
        "specm=np.mean(spec,axis=0)\n",
        "\n",
        "#compute power gradient across time points\n",
        "gradm=np.gradient(specm)\n",
        "\n",
        "#set max to 1\n",
        "gradm=gradm/np.max(gradm)\n",
        "\n",
        "#set negative gradient time points to zero \n",
        "gradm = gradm.clip(min=0)\n",
        "    \n",
        "#normalize mean power between 0-1\n",
        "specm=(specm-np.min(specm))/np.ptp(specm)\n",
        "\n",
        "#create chromagram of pitches X time points\n",
        "chroma = librosa.feature.chroma_cqt(y=y, sr=sr, hop_length=frame_length)\n",
        "\n",
        "#sort pitches by overall power \n",
        "chromasort=np.argsort(np.mean(chroma,axis=1))[::-1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj13dtNdpx_I"
      },
      "source": [
        "cls1000=list(range(1000))\n",
        "random.shuffle(cls1000)\n",
        "classes=cls1000[:12]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbeTetcTxDxy"
      },
      "source": [
        "cv1=np.zeros(1000)\n",
        "for pi,p in enumerate(chromasort[:num_classes]):\n",
        "    \n",
        "    if num_classes < 12:\n",
        "        cv1[classes[pi]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]       \n",
        "    else:\n",
        "        cv1[classes[p]] = chroma[p][np.min([np.where(chrow>0)[0][0] for chrow in chroma])]\n",
        "\n",
        "#initialize first noise vector\n",
        "nv1 = truncated_noise_sample(truncation=truncation)[0]\n",
        "\n",
        "#initialize list of class and noise vectors\n",
        "class_vectors=[cv1]\n",
        "noise_vectors=[nv1]\n",
        "\n",
        "#initialize previous vectors (will be used to track the previous frame)\n",
        "cvlast=cv1\n",
        "nvlast=nv1\n",
        "\n",
        "\n",
        "\n",
        "#initialize the direction of noise vector unit updates\n",
        "update_dir=np.zeros(128)\n",
        "for ni,n in enumerate(nv1):\n",
        "    if n<0:\n",
        "        update_dir[ni] = 1\n",
        "    else:\n",
        "        update_dir[ni] = -1\n",
        "\n",
        "\n",
        "#initialize noise unit update\n",
        "update_last=np.zeros(128)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWNc6kmOxD7V",
        "outputId": "5744db5e-a87a-45b4-a071-52ca713b3af3"
      },
      "source": [
        "#get new jitters\n",
        "def new_jitters(jitter):\n",
        "    jitters=np.zeros(128)\n",
        "    for j in range(128):\n",
        "        if random.uniform(0,1)<0.5:\n",
        "            jitters[j]=1\n",
        "        else:\n",
        "            jitters[j]=1-jitter        \n",
        "    return jitters\n",
        "\n",
        "\n",
        "#get new update directions\n",
        "def new_update_dir(nv2,update_dir):\n",
        "    for ni,n in enumerate(nv2):                  \n",
        "        if n >= 2*truncation - tempo_sensitivity:\n",
        "            update_dir[ni] = -1  \n",
        "                        \n",
        "        elif n < -2*truncation + tempo_sensitivity:\n",
        "            update_dir[ni] = 1   \n",
        "    return update_dir\n",
        "\n",
        "\n",
        "#smooth class vectors\n",
        "def smooth(class_vectors,smooth_factor):\n",
        "    \n",
        "    if smooth_factor==1:\n",
        "        return class_vectors\n",
        "    \n",
        "    class_vectors_terp=[]\n",
        "    for c in range(int(np.floor(len(class_vectors)/smooth_factor)-1)):  \n",
        "        ci=c*smooth_factor          \n",
        "        cva=np.mean(class_vectors[int(ci):int(ci)+smooth_factor],axis=0)\n",
        "        cvb=np.mean(class_vectors[int(ci)+smooth_factor:int(ci)+smooth_factor*2],axis=0)\n",
        "                    \n",
        "        for j in range(smooth_factor):                                 \n",
        "            cvc = cva*(1-j/(smooth_factor-1)) + cvb*(j/(smooth_factor-1))                                          \n",
        "            class_vectors_terp.append(cvc)\n",
        "            \n",
        "    return np.array(class_vectors_terp)\n",
        "\n",
        "\n",
        "#normalize class vector between 0-1\n",
        "def normalize_cv(cv2):\n",
        "    min_class_val = min(i for i in cv2 if i != 0)\n",
        "    for ci,c in enumerate(cv2):\n",
        "        if c==0:\n",
        "            cv2[ci]=min_class_val    \n",
        "    cv2=(cv2-min_class_val)/np.ptp(cv2) \n",
        "    \n",
        "    return cv2\n",
        "\n",
        "\n",
        "print('\\nGenerating input vectors \\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Generating input vectors \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Bs2nSxxUAj",
        "outputId": "c826ef3f-9e04-4d0d-82bb-e75f081e560b"
      },
      "source": [
        "#train\n",
        "for i in tqdm(range(len(gradm))):   \n",
        "    \n",
        "    #print progress\n",
        "    pass\n",
        "    \n",
        "\n",
        "    #update jitter vector every 100 frames by setting ~half of noise vector units to lower sensitivity\n",
        "    if i%200==0:\n",
        "        jitters=new_jitters(jitter)\n",
        "\n",
        "    #get last noise vector\n",
        "    nv1=nvlast\n",
        "\n",
        "    #set noise vector update based on direction, sensitivity, jitter, and combination of overall power and gradient of power\n",
        "    update = np.array([tempo_sensitivity for k in range(128)]) * (gradm[i]+specm[i]) * update_dir * jitters \n",
        "    \n",
        "    #smooth the update with the previous update (to avoid overly sharp frame transitions)\n",
        "    update=(update+update_last*3)/4\n",
        "    \n",
        "    #set last update\n",
        "    update_last=update\n",
        "        \n",
        "    #update noise vector\n",
        "    nv2=nv1+update\n",
        "\n",
        "    #append to noise vectors\n",
        "    noise_vectors.append(nv2)\n",
        "    \n",
        "    #set last noise vector\n",
        "    nvlast=nv2\n",
        "                   \n",
        "    #update the direction of noise units\n",
        "    update_dir=new_update_dir(nv2,update_dir)\n",
        "\n",
        "    #get last class vector\n",
        "    cv1=cvlast\n",
        "    \n",
        "    #generate new class vector\n",
        "    cv2=np.zeros(1000)\n",
        "    for j in range(num_classes):\n",
        "        \n",
        "        cv2[classes[j]] = (cvlast[classes[j]] + ((chroma[chromasort[j]][i])/(pitch_sensitivity)))/(1+(1/((pitch_sensitivity))))\n",
        "\n",
        "    #if more than 6 classes, normalize new class vector between 0 and 1, else simply set max class val to 1\n",
        "    if num_classes > 6:\n",
        "        cv2=normalize_cv(cv2)\n",
        "    else:\n",
        "        cv2=cv2/np.max(cv2)\n",
        "    \n",
        "    #adjust depth    \n",
        "    cv2=cv2*depth\n",
        "    \n",
        "    #this prevents rare bugs where all classes are the same value\n",
        "    if np.std(cv2[np.where(cv2!=0)]) < 0.0000001:\n",
        "        cv2[classes[0]]=cv2[classes[0]]+0.01\n",
        "\n",
        "    #append new class vector\n",
        "    class_vectors.append(cv2)\n",
        "    \n",
        "    #set last class vector\n",
        "    cvlast=cv2\n",
        "\n",
        "\n",
        "#interpolate between class vectors of bin size [smooth_factor] to smooth frames \n",
        "class_vectors=smooth(class_vectors,smooth_factor)\n",
        "\n",
        "\n",
        "\n",
        "np.save('class_vectors.npy',class_vectors)\n",
        "\n",
        "np.save('noise_vectors.npy',noise_vectors)\n",
        "\n",
        "\n",
        "#convert to Tensor\n",
        "noise_vectors = torch.Tensor(np.array(noise_vectors))      \n",
        "class_vectors = torch.Tensor(np.array(class_vectors))      \n",
        "\n",
        "\n",
        "#Generate frames in batches of batch_size\n",
        "\n",
        "print('\\n\\nGenerating frames \\n')\n",
        "\n",
        "#send to CUDA if running on GPU\n",
        "model=model.to(device)\n",
        "noise_vectors=noise_vectors.to(device)\n",
        "class_vectors=class_vectors.to(device)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1785/1785 [00:01<00:00, 1034.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Generating frames \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgcxET-JpyYl",
        "outputId": "5d7d71e8-82ff-4a8f-ef0f-264a01c02929"
      },
      "source": [
        "frames = []\n",
        "\n",
        "for i in tqdm(range(frame_lim)):\n",
        "    \n",
        "    #print progress\n",
        "    pass\n",
        "\n",
        "    if (i+1)*batch_size > len(class_vectors):\n",
        "        torch.cuda.empty_cache()\n",
        "        break\n",
        "    \n",
        "    #get batch\n",
        "    noise_vector=noise_vectors[i*batch_size:(i+1)*batch_size]\n",
        "    class_vector=class_vectors[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "    # Generate images\n",
        "    with torch.no_grad():\n",
        "        output = model(noise_vector, class_vector, truncation)\n",
        "\n",
        "    output_cpu=output.cpu().data.numpy()\n",
        "\n",
        "    #convert to image array and add to frames\n",
        "    for out in output_cpu:    \n",
        "        im=np.array(toimage(out))\n",
        "        frames.append(im)\n",
        "        \n",
        "    #empty cuda cache\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "#Save video  \n",
        "aud = mpy.AudioFileClip(song_path, fps = 44100) \n",
        "\n",
        "\n",
        "clip = mpy.ImageSequenceClip(frames, fps=22050/frame_length)\n",
        "clip = clip.set_audio(aud)\n",
        "clip.write_videofile(outname,audio_codec='aac')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 58/58 [01:23<00:00,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video out.mp4\n",
            "[MoviePy] Writing audio in outTEMP_MPY_wvf_snd.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 915/915 [00:01<00:00, 603.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] Writing video out.mp4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1740/1740 [00:38<00:00, 44.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: out.mp4 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6PmYdPrp8M2"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "from base64 import b64encode\n",
        "mp4 = open('out.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nkhnF7luEYD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}